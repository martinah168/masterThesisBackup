{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#from sklearn.manifold import TSNE\n",
    "import os\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from math import floor\n",
    "import random\n",
    "from torch.utils.data import  Dataset\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 15.87 M\n"
     ]
    }
   ],
   "source": [
    "from pl_models.DEA import DAE_LitModel\n",
    "\n",
    "\n",
    "pl_model = DAE_LitModel.load_from_checkpoint(\"/media/data/robert/code/DiffAE/lightning_logs/DAE_NAKO_256/version_1/checkpoints/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/media/data/robert/code/nako_embedding/dataset/data/train/1004/100400_HWS_07.png\"\n",
    "\n",
    "# from dataloader.dataset_factory import get_dataset, get_data_loader\n",
    "\n",
    "# val_data = get_dataset(pl_model.conf, split=\"val\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#    i: Tensor = val_data[0][\"img\"]\n",
    "#    i = i.unsqueeze(0).cuda()\n",
    "#    i.shape\n",
    "#    emb = pl_model.model.encode(i).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_creation(daten, label):\n",
    "    occurences = daten[label].to_list()\n",
    "    occurences.sort()\n",
    "    occurences = list(dict.fromkeys(occurences))\n",
    "    label_dict = {}\n",
    "    for i in range(len(occurences)):\n",
    "        ky = occurences[i]\n",
    "        label_dict[ky] = i\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "root = \"/media/data/robert/code/nako_embedding/\"\n",
    "\n",
    "def_dir = Path(root) / \"dataset/vibe/split.csv\"\n",
    "\n",
    "\n",
    "class EnocderSet(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory=def_dir,\n",
    "        # dorsal=None,\n",
    "        path=None,\n",
    "        drop_mean=False,\n",
    "        transform=None,\n",
    "        region_of_interest=\"random\",\n",
    "        slice=\"center\",\n",
    "        target_transform=None,\n",
    "        target_label=[\"PatientSex\", \"PatientAge\", \"PatientWeight\", \"PatientSize\"],\n",
    "        # ind=-150,\n",
    "        # three_D=None,\n",
    "        split=\"all\",  # \"train\",\n",
    "        return_row=False,\n",
    "    ):\n",
    "        super(EnocderSet, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The target label can be switched to:\n",
    "        PatientSex\n",
    "        PatientAge\n",
    "        PatientSize\n",
    "        PatientWeight\n",
    "        \"\"\"\n",
    "        # load the .csv which was created previously\n",
    "\n",
    "        # self.three_D = three_D\n",
    "        # self.dorsal = dorsal\n",
    "        self.path = path\n",
    "        self.target_label = target_label\n",
    "        self.directory = directory\n",
    "        # self.ind = ind\n",
    "        self.name = \"StyleGAN2-Dataset\"\n",
    "        self.drop_mean = drop_mean\n",
    "        self.region_of_interest = region_of_interest\n",
    "        self.slice = slice\n",
    "        dataframe = pd.DataFrame(pd.read_csv(directory))\n",
    "\n",
    "        if split != \"all\":\n",
    "            dataframe = pd.DataFrame(pd.read_csv(directory))\n",
    "            self.dataset = dataframe.loc[dataframe[\"Split\"] > split]\n",
    "            self.dataset.reset_index(inplace=True)\n",
    "        else:\n",
    "            self.dataset = dataframe\n",
    "        if drop_mean == True:\n",
    "            self.dataset = self.dataset.drop(self.dataset[(self.dataset[\"PatientAge\"] > 27) & (self.dataset[\"PatientAge\"] < 37)].index)\n",
    "            self.dataset.reset_index(inplace=True)\n",
    "        # self.dataset = pd.read_csv(directory)[:ind]\n",
    "\n",
    "        print(\"len = \", len(self.dataset))\n",
    "\n",
    "        self.age_count = self.dataset[\"PatientAge\"].nunique()\n",
    "        self.weight_count = self.dataset[\"PatientWeight\"].nunique()\n",
    "        self.size_count = self.dataset[\"PatientSize\"].nunique()\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.return_row = return_row\n",
    "\n",
    "        length_dict = {\n",
    "            \"PatientSex\": 2,\n",
    "            \"PatientAge\": self.age_count,\n",
    "            \"PatientWeight\": self.weight_count,\n",
    "            \"PatientSize\": self.size_count,\n",
    "        }\n",
    "\n",
    "        self.ind = [2, self.age_count, self.weight_count, self.size_count]\n",
    "\n",
    "        # for keys in length_dict.keys():\n",
    "        #    print(keys + \" dictionary is \", length_dict[keys], \" long\")\n",
    "        self.num_img = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def get_max_files(self, index, roi):\n",
    "        row = self.dataset.iloc[index]\n",
    "        id = f'{row[\"PatientID\"]}_{roi}'\n",
    "        if id not in self.num_img:\n",
    "            p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "            self.num_img[id] = len(list(p2.glob(id + \"_*.png\")))\n",
    "        return self.num_img[id]\n",
    "\n",
    "    def get_item(self, index, slice=None, roi=None):\n",
    "        row = self.dataset.iloc[index]\n",
    "        if roi is None:\n",
    "            roi = self.region_of_interest\n",
    "        if roi == \"random\":\n",
    "            roi = [\"LWS\", \"HWS\", \"BWS\"][random.randint(0, 2)]\n",
    "\n",
    "        p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "        if slice is not None:\n",
    "            i = slice\n",
    "            if self.get_max_files(index, roi) >= i:\n",
    "                return None, []\n",
    "        elif self.slice == \"random\":\n",
    "            i = random.randint(0, self.get_max_files(index, roi) - 1)\n",
    "        elif self.slice == \"center\":\n",
    "            i = self.get_max_files(index, roi) // 2\n",
    "        else:\n",
    "            i = self.slice  # TODO\n",
    "        im_path = Path(p2, f'{row[\"PatientID\"]}_{roi}_{i:02}.png')\n",
    "        # print(im_path)\n",
    "        if not im_path.exists():\n",
    "            raise FileNotFoundError(im_path)\n",
    "\n",
    "        img_array = Image.open(im_path)\n",
    "        img_array = img_array.convert(\"L\")\n",
    "        if self.transform:\n",
    "            img_array = self.transform(img_array)\n",
    "\n",
    "        if self.return_row:\n",
    "            return img_array, row\n",
    "        target = []\n",
    "        if type(self.target_label) == str:\n",
    "            target = self.dataset.loc[index, self.target_label]\n",
    "        elif type(self.target_label) == list:\n",
    "            for i, label in enumerate(self.target_label):\n",
    "                target.append(self.dataset.loc[index, label])\n",
    "\n",
    "        return img_array, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_item(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path /media/data/robert/code/DiffAE/lightning_logs/DAE_NAKO_256/version_1/checkpoints/last.ckpt\n",
      "[1] Reload Encoder4Editing\n",
      "Model params: 15.87 M\n",
      "[2] load dataset\n",
      "len =  10823\n",
      "[3] encode dataset\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We found 11189 patients in the NAKO dataset where all three regions exist without duplicate. We initially split the dataset patient wise into train/val/test set 80/5/15\n",
    "We generate with the encoding an embedding for every image. We use the center crop for every image.\n",
    "\n",
    "We concatenate 12 slice to improve our T-SNE plots\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ROWS:\n",
    "    PatientID: str\n",
    "\n",
    "\n",
    "from pl_models.DEA import DAE_LitModel\n",
    "\n",
    "pd_org = pandas.read_csv(root + \"dataset/split.csv\")\n",
    "checkpoint_path = \"/media/data/robert/code/DiffAE/lightning_logs/DAE_NAKO_256/version_1/checkpoints/last.ckpt\"\n",
    "device: str | None = \"cuda:0\"\n",
    "print(\"checkpoint_path\", checkpoint_path)\n",
    "assert Path(checkpoint_path).exists()\n",
    "\n",
    "print(\"[1] Reload Encoder4Editing\")\n",
    "encoder = DAE_LitModel.load_from_checkpoint(checkpoint_path)\n",
    "print(\"[2] load dataset\")\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.CenterCrop(256), transforms.Normalize([0.5], [0.5])])\n",
    "encoder_set = EnocderSet(transform=transformation, return_row=True)\n",
    "# loader = DataLoader(encoder_set, batch_size=4)\n",
    "print(\"[3] encode dataset\")\n",
    "\n",
    "\n",
    "def encode(encoder_set: EnocderSet, id, roi):\n",
    "    real_images, label = encoder_set.get_item(id, slice=None, roi=roi)  # type: ignore\n",
    "    label: ROWS\n",
    "    real_images = torch.as_tensor(real_images, device=device).unsqueeze_(0)  # type: ignore\n",
    "    real_images = real_images.to(device)\n",
    "    latent_code: torch.Tensor = pl_model.model.encode(real_images).to(device)  #\n",
    "    return latent_code, label\n",
    "\n",
    "\n",
    "def encode_multi(encoder_set: EnocderSet, id, roi):\n",
    "    offset = (encoder_set.get_max_files(id, roi) - 12) // 2\n",
    "    label: ROWS = None  # type: ignore\n",
    "    latent_codes = []\n",
    "    for i in range(offset, offset + 12):\n",
    "        real_images, label = encoder_set.get_item(id, slice=None, roi=roi)  # type: ignore\n",
    "        real_images = torch.as_tensor(real_images, device=device).unsqueeze_(0)  # type: ignore\n",
    "        real_images = real_images.to(device)\n",
    "        latent_code: torch.Tensor = pl_model.model.encode(real_images).to(device)  #\n",
    "        latent_codes.append(latent_code)\n",
    "    return torch.cat(latent_codes), label\n",
    "\n",
    "\n",
    "latent_code, label = encode(encoder_set, 0, \"BWS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] encode dataset\n",
      "len =  10823\n",
      "[5]     11 /  10823                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/data/robert/code/dae/test_vibe.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m latent_code2, label2 \u001b[39m=\u001b[39m encode_multi(encoder_set, i, \u001b[39m\"\u001b[39m\u001b[39mBWS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m latent_code3, label3 \u001b[39m=\u001b[39m encode_multi(encoder_set, i, \u001b[39m\"\u001b[39;49m\u001b[39mLWS\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39massert\u001b[39;00m label1\u001b[39m.\u001b[39mPatientID \u001b[39m==\u001b[39m label2\u001b[39m.\u001b[39mPatientID\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39massert\u001b[39;00m label1\u001b[39m.\u001b[39mPatientID \u001b[39m==\u001b[39m label3\u001b[39m.\u001b[39mPatientID\n",
      "\u001b[1;32m/media/data/robert/code/dae/test_vibe.ipynb Cell 8\u001b[0m in \u001b[0;36mencode_multi\u001b[0;34m(encoder_set, id, roi)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m latent_codes \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(offset, offset \u001b[39m+\u001b[39m \u001b[39m12\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     real_images, label \u001b[39m=\u001b[39m encoder_set\u001b[39m.\u001b[39;49mget_item(\u001b[39mid\u001b[39;49m, \u001b[39mslice\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, roi\u001b[39m=\u001b[39;49mroi)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     real_images \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(real_images, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39munsqueeze_(\u001b[39m0\u001b[39m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     real_images \u001b[39m=\u001b[39m real_images\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;32m/media/data/robert/code/dae/test_vibe.ipynb Cell 8\u001b[0m in \u001b[0;36mEnocderSet.get_item\u001b[0;34m(self, index, slice, roi)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m im_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(im_path)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m img_array \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(im_path)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m img_array \u001b[39m=\u001b[39m img_array\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/data/robert/code/dae/test_vibe.ipynb#X10sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.10.11/lib/python3.10/site-packages/PIL/Image.py:3140\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3137\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fp\u001b[39m.\u001b[39mread())\n\u001b[1;32m   3138\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 3140\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(\u001b[39m16\u001b[39;49m)\n\u001b[1;32m   3142\u001b[0m preinit()\n\u001b[1;32m   3144\u001b[0m accept_warnings \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"[4] encode dataset\")\n",
    "\n",
    "encoder_set = EnocderSet(transform=transformation, return_row=True, region_of_interest=\"HWS\", slice=\"center\")\n",
    "dic = {}\n",
    "l = len(encoder_set)\n",
    "slice = \"DEA_vibe\"\n",
    "file = root + f\"/dataset/embeddings_{slice}_stack.pkl\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "if Path(file).exists():\n",
    "    with open(file, \"rb\") as f:\n",
    "        dic = pickle.load(f)\n",
    "        print(len(dic))\n",
    "\n",
    "count = {k: 0 for k in range(20)}\n",
    "with torch.no_grad():\n",
    "    for i in range(l):\n",
    "        count[encoder_set.get_max_files(i, \"LWS\")] += 1\n",
    "        try:\n",
    "            latent_code1, label1 = encode_multi(encoder_set, i, \"HWS\")  #\n",
    "            # print(label.PatientID)\n",
    "            if label1.PatientID in dic:\n",
    "                continue\n",
    "            latent_code2, label2 = encode_multi(encoder_set, i, \"BWS\")\n",
    "            latent_code3, label3 = encode_multi(encoder_set, i, \"LWS\")\n",
    "            assert label1.PatientID == label2.PatientID\n",
    "            assert label1.PatientID == label3.PatientID\n",
    "            dic[label1.PatientID] = (label1, latent_code1.cpu(), latent_code2.cpu(), latent_code3.cpu())\n",
    "            print(f\"[5] {i:6} / {l:6}                                             \", end=\"\\r\")\n",
    "            # assert i + 1 == len(dic), (i + 1, len(dic))\n",
    "            if i % 1001 == 1000:\n",
    "                with open(file, \"wb\") as f:\n",
    "                    pickle.dump(dic, f)\n",
    "        except Exception as e:\n",
    "            # raise e\n",
    "            print(e)\n",
    "with open(file, \"wb\") as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_list = []\n",
    "\n",
    "print(\"[5] encode dataset\")\n",
    "p = Path(root, f\"dataset/vibe/train_DAE.csv\")\n",
    "print(p)\n",
    "data = []\n",
    "mapping = {\"BWS\": \"thoracic\", \"HWS\": \"cervical\", \"LWS\": \"lumbar\"}\n",
    "for k in dic.keys():\n",
    "    print(k, end=\"\\r\")\n",
    "    for roi in [\"BWS\", \"HWS\", \"LWS\"]:\n",
    "        row = dic[k][0].copy()\n",
    "        id = f'{row[\"PatientID\"]}_{roi}'\n",
    "        p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "        v = len(list(p2.glob(id + \"_*.png\")))\n",
    "        for i in range(v):\n",
    "            row = dic[k][0].copy()\n",
    "            p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "            row[\"file_path\"] = str(Path(p2, f'{row[\"PatientID\"]}_{roi}_{i:02}.png'))\n",
    "            row[\"roi\"] = mapping[roi]\n",
    "\n",
    "            data.append(row.copy())\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(p)\n",
    "# df = pd.concat(data, columns=[\"PatientID\"])\n",
    "# print(df)\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6bb3a75c423b55141fce25809192a6cd1ff47641b121a214d3a7a5d8c58a372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
