{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e ~/coding/diffae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "from training.data.glioma_public import PublicGliomaDataset\n",
    "from training.data.mri import extract_slices_from_volume\n",
    "from training.experiments.cls import ClsModel\n",
    "from training.experiments.rep import LitModel\n",
    "from training.templates.templates import gliomapublic_autoenc\n",
    "from training.templates.templates_cls import gliomapublic_autoenc_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = %pwd\n",
    "CWD = Path(CWD).parent\n",
    "CWD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEED = 0\n",
    "np.random.seed(SEEED)\n",
    "torch.manual_seed(SEEED)\n",
    "print(f\"seed = {SEEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tensor(t, ax, cmap=\"gray\", *args, **kwargs):\n",
    "    return ax.imshow(t.permute(1, 2, 0).cpu(), cmap=cmap, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.clf_mode = \"multi_class\"\n",
    "args.manipulate_znormalize = False\n",
    "# args.manipulate_cls = \"12\"\n",
    "args.model_name = \"beatgans_autoenc\"\n",
    "args.version = \"5\"  # \"2\" or \"5\" for the other model\n",
    "args.style_ch = \"512\"\n",
    "args.use_healthy = True\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "conf = gliomapublic_autoenc(args=args, is_debugging=False)\n",
    "\n",
    "state = torch.load(CWD / f'{conf.logdir}/last.ckpt', map_location='cpu')\n",
    "conf.sample_size = state[\"state_dict\"][\"x_T\"].shape[0]\n",
    "conf.manipulate_znormalize = False\n",
    "print(conf.name)\n",
    "model = LitModel(conf)\n",
    "model.load_state_dict(state['state_dict'], strict=False)\n",
    "model.ema_model.eval()\n",
    "model.ema_model.to(device)\n",
    "args.pretrain_path = CWD / f\"checkpoints/gliomapublic_seq-all/version_{args.version}/last.ckpt\"\n",
    "print(\"version setup for healthy visualization\")\n",
    "args.version = {\"2\": \"0\", \"5\": \"1\"}[args.version]\n",
    "cls_conf = gliomapublic_autoenc_cls(is_debugging=False, args=args)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model = ClsModel(cls_conf)\n",
    "cls_state = torch.load(CWD / f'{cls_conf.logdir}/last.ckpt', map_location='cpu')\n",
    "print('latent step:', cls_state['global_step'])\n",
    "cls_model.load_state_dict(cls_state['state_dict'], strict=False)\n",
    "cls_model.to(device)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_state[\"state_dict\"][\"classifier.weight\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "split = \"train\"\n",
    "ds = PublicGliomaDataset(\n",
    "    data_dir=conf.data_path,\n",
    "    img_size=conf.img_size,\n",
    "    mri_sequences=conf.mri_sequences,\n",
    "    mri_crop=conf.mri_crop,\n",
    "    train_mode=conf.train_mode,\n",
    "    filter_class_labels=True,\n",
    "    split_ratio=conf.split_ratio,\n",
    "    split=split,\n",
    "    manipulate_cls=conf.manipulate_cls,\n",
    "    use_healthy=conf.use_healthy,\n",
    ")\n",
    "n_classes = ds.num_classes\n",
    "n_seq = ds.n_seq\n",
    "print(f\"{n_classes = }, {n_seq = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single sample from the dataset\n",
    "i_data = np.random.randint(0, len(ds))\n",
    "\n",
    "print(f\"index in dataset: {i_data}\")\n",
    "sample_dict = ds[i_data]\n",
    "for k, v in sample_dict.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        sample_dict[k] = v.to(device).unsqueeze(0)\n",
    "\n",
    "edit_img = sample_dict['img']\n",
    "cls_label = sample_dict[\"cls_labels\"]\n",
    "# flip class label\n",
    "\n",
    "cls_label = torch.tensor(0 if cls_label == 1 else 1)\n",
    "print(f\"flipped class label to {cls_label.item()}\")\n",
    "com = sample_dict[\"com\"]\n",
    "if conf.clf_mode != \"multi_class\" and not conf.use_healthy:\n",
    "    og_class_label = ds.inv_cls_label_map[cls_label.item()]\n",
    "else:\n",
    "    og_class_label = cls_label.item()\n",
    "\n",
    "og_class_label_name = ds.cls_to_name[\n",
    "    og_class_label] if not conf.use_healthy else {\n",
    "        1: \"healthy\",\n",
    "        0: \"tumor\"\n",
    "    }[og_class_label]\n",
    "\n",
    "print(\n",
    "    f\"img has class {og_class_label} ({og_class_label_name}), binary cls label: {cls_label.item()}\"\n",
    ")\n",
    "# show the sampled volume from the dataset\n",
    "img_slices = extract_slices_from_volume(edit_img, com)\n",
    "seg_slices = extract_slices_from_volume(\n",
    "    sample_dict['seg'].repeat(1, ds.n_seq, 1, 1, 1), com)\n",
    "\n",
    "with_seg_map = True\n",
    "\n",
    "fig = plt.figure(figsize=(5, 8))\n",
    "for i in range(3 * n_seq):\n",
    "    ax = fig.add_subplot(n_seq, 3, i + 1)\n",
    "    plot_tensor(img_slices[i], ax)\n",
    "    if with_seg_map:\n",
    "        plot_tensor(seg_slices[i],\n",
    "                    ax,\n",
    "                    cmap=\"jet\",\n",
    "                    alpha=0.2 * (seg_slices[i][0].detach().cpu().numpy() > 0))\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_fast = 10\n",
    "T_slow = 200\n",
    "T = T_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = model.encode(edit_img)\n",
    "print(\"cond size:\", cond.size())\n",
    "xT = model.encode_stochastic(edit_img, cond, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_slice = extract_slices_from_volume(edit_img, com)\n",
    "xT_slice = extract_slices_from_volume(xT, com)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "show_dict = dict(cmap=\"gray\")\n",
    "for a, t in zip(ax, [img_slice[0], xT_slice[0]]):\n",
    "    plot_tensor(t, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new conditional vector with a different class label\n",
    "l_cond = 0.2\n",
    "# because we need to transfer the label to the negative class.\n",
    "l_cond = -1 * l_cond if cls_label.item() == 1 else l_cond\n",
    "if cls_conf.manipulate_znormalize:\n",
    "    cond2 = cls_model.normalize(cond)\n",
    "else:\n",
    "    cond2 = cond\n",
    "clf_hyperplane = F.normalize(cls_model.classifier.weight, dim=1)\n",
    "\n",
    "cond2 = cond2 + l_cond * np.sqrt(conf.style_ch) * clf_hyperplane\n",
    "if cls_conf.manipulate_znormalize:\n",
    "    cond2 = cls_model.denormalize(cond2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: classifier should give positive and negative values for the two classes\n",
    "pred = cls_model.classifier(cond)\n",
    "if (pred > 0) != (cls_label.item() == 1):\n",
    "    print(\"WARNING: classifier gave wrong prediction!\")\n",
    "edit_pred = cls_model.classifier(cond2)\n",
    "print(f\"pred: {pred.item():.2f}, edit_pred: {edit_pred.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_cls_label = (cls_model.classifier(cond2) > 0).int()\n",
    "og_edit_cls_label = ds.inv_cls_label_map[\n",
    "    edit_cls_label.item()] if not conf.use_healthy else edit_cls_label.item()\n",
    "\n",
    "assert og_edit_cls_label != og_class_label, \"class label should be different\"\n",
    "\n",
    "print(\n",
    "    f\"binary class label, og: {cls_label.item()}, new: {edit_cls_label.item()}\")\n",
    "og_edit_class_label_name = {\n",
    "    0: \"tumor\",\n",
    "    1: \"healthy\"\n",
    "}[og_edit_cls_label] if conf.use_healthy else ds.cls_to_name[og_edit_cls_label]\n",
    "\n",
    "print(\n",
    "    f\"original class label: {og_class_label} ({og_class_label_name}), new: {og_edit_cls_label} ({og_edit_class_label_name})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image with different class\n",
    "edit_img = model.render(xT, cond2, T=T)\n",
    "edit_img_slice = extract_slices_from_volume(edit_img, com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manip_img_dir = CWD / \"imgs_manipulated/mri\"\n",
    "(manip_img_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slice = 1\n",
    "\n",
    "stride = 1 if n_slice == 3 else 3\n",
    "# only show axial slices of the mri\n",
    "img_slice_strided = img_slice[::stride]\n",
    "edit_img_slice_strided = edit_img_slice[::stride]\n",
    "diff_images = (edit_img_slice_strided - img_slice_strided).abs()\n",
    "\n",
    "imgs = torch.stack([img_slice_strided, edit_img_slice_strided, diff_images],\n",
    "                   dim=1).view(-1, *img_slice_strided[0].size())\n",
    "\n",
    "n_row = n_seq * n_slice\n",
    "fig, axs = plt.subplots(n_row,\n",
    "                        imgs.size(0) // n_row,\n",
    "                        figsize=(imgs.size(0) // n_row, n_row + 1))\n",
    "\n",
    "seqs = [\"T1\", \"T1CE\", \"T2\", \"FLAIR\"]\n",
    "img_mode = [\"\", \"EDIT\", \"DIFF\"]\n",
    "\n",
    "og_class_label = ds.inv_cls_label_map[\n",
    "    cls_label.item()] if not conf.use_healthy else cls_label.item()\n",
    "edit_og_class_label = ds.inv_cls_label_map[\n",
    "    edit_cls_label.item()] if not conf.use_healthy else edit_cls_label.item()\n",
    "fig.suptitle(f\"Class {og_class_label} -> {edit_og_class_label}\")\n",
    "\n",
    "for i, (img, ax) in enumerate(zip(imgs, axs.flatten())):\n",
    "    plot_tensor(img, ax)\n",
    "    ax.axis(\"off\")\n",
    "    cur_seq = seqs[i // 3]\n",
    "    cur_mode = img_mode[i % 3]\n",
    "    title = f\"{cur_seq} {cur_mode}\"\n",
    "    ax.title.set_text(title)\n",
    "\n",
    "plt.tight_layout(h_pad=0, w_pad=1)\n",
    "manipulation_str = f\"manipulate_{og_class_label}_to_{edit_og_class_label}\"\n",
    "fp = manip_img_dir / f'compare_mri_{manipulation_str}_{split}{\"_healthy\" if conf.use_healthy else \"\"}{args.version}.png'\n",
    "plt.savefig(fp)\n",
    "print(f\"saved to {fp}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images to nifti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import SaveImage, SaveImaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_img.max(), edit_img.min(), edit_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast image to uint8 in range [0, 255] for saving\n",
    "edit_img_byte = edit_img.clamp(-1, 1).add(1).div(2).mul(255).to(torch.uint8)\n",
    "print(\n",
    "    f\"edit_img_byte: {edit_img_byte.max()}, {edit_img_byte.min()}, {edit_img_byte.size()}\"\n",
    ")\n",
    "\n",
    "save_img_dict = dict(zip(conf.mri_sequences, edit_img_byte[0]))\n",
    "# determine sequence name used for all filenames\n",
    "cur_seq_name = [\n",
    "    c for c in conf.mri_sequences if c in edit_img_byte.meta[\"filename_or_obj\"]\n",
    "][0]\n",
    "# update meta dict to contain original sequence name in filename\n",
    "for seq, img in save_img_dict.items():\n",
    "    img.meta[\"filename_or_obj\"] = img.meta[\"filename_or_obj\"].replace(\n",
    "        cur_seq_name, seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the Nibabel backend\n",
    "subject_id = ds._make_patient_id(ds.subject_dirs[i_data])\n",
    "editing_type = \"\"\n",
    "if conf.use_healthy:\n",
    "    editing_type = \"healthy_to_tumor\" if og_class_label == 1 else \"tumor_to_healthy\"\n",
    "else:\n",
    "    raise NotImplementedError(\"only healthy vs tumor implemented\")\n",
    "\n",
    "saver = SaveImaged(keys=conf.mri_sequences,\n",
    "                   output_dir=manip_img_dir / subject_id / editing_type,\n",
    "                   output_postfix='',\n",
    "                   output_ext=\".nii.gz\",\n",
    "                   output_dtype=np.uint8,\n",
    "                   resample=False,\n",
    "                   squeeze_end_dims=True,\n",
    "                   writer=\"NibabelWriter\",\n",
    "                   separate_folder=False)\n",
    "\n",
    "saver(save_img_dict)\n",
    "print(f\"saved to {manip_img_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f8f14ac2789a61c7d4a4890af4638ffd689245691e5b64d8cd36864be5139b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
