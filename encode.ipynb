{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#from sklearn.manifold import TSNE\n",
    "import os\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from math import floor\n",
    "import random\n",
    "from torch.utils.data import  Dataset\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 15.87 M\n"
     ]
    }
   ],
   "source": [
    "from pl_models.DEA import DAE_LitModel\n",
    "\n",
    "hessian = True\n",
    "if hessian:\n",
    "    pl_model = DAE_LitModel.load_from_checkpoint(\n",
    "        \"/media/data/robert/code/dae/lightning_logs/DAE_NAKO_256_hessian_penalty_1/version_4/checkpoints/last.ckpt\"\n",
    "    )\n",
    "else:\n",
    "    pl_model = DAE_LitModel.load_from_checkpoint(\"/media/data/robert/code/dae/lightning_logs/DAE_NAKO_256/version_1/checkpoints/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/data/robert/code/nako_embedding/dataset/train.csv\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "# path = \"/media/data/robert/code/nako_embedding/dataset/data/train/1004/100400_HWS_07.png\"\n",
    "\n",
    "from dataloader.dataset_factory import get_dataset, get_data_loader\n",
    "\n",
    "val_data = get_dataset(pl_model.conf, split=\"val\")\n",
    "with torch.no_grad():\n",
    "    i: Tensor = val_data[0][\"img\"]\n",
    "    i = i.unsqueeze(0).cuda()\n",
    "    i.shape\n",
    "    emb = pl_model.model.encode(i).cpu()\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_creation(daten, label):\n",
    "    occurences = daten[label].to_list()\n",
    "    occurences.sort()\n",
    "    occurences = list(dict.fromkeys(occurences))\n",
    "    label_dict = {}\n",
    "    for i in range(len(occurences)):\n",
    "        ky = occurences[i]\n",
    "        label_dict[ky] = i\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "root = \"/media/data/robert/code/nako_embedding/\"\n",
    "\n",
    "def_dir = Path(root) / \"dataset/split.csv\"\n",
    "\n",
    "\n",
    "class EnocderSet(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory=def_dir,\n",
    "        # dorsal=None,\n",
    "        path=None,\n",
    "        drop_mean=False,\n",
    "        transform=None,\n",
    "        region_of_interest=\"random\",\n",
    "        slice=\"center\",\n",
    "        target_transform=None,\n",
    "        target_label=[\"PatientSex\", \"PatientAge\", \"PatientWeight\", \"PatientSize\"],\n",
    "        # ind=-150,\n",
    "        # three_D=None,\n",
    "        split=\"all\",  # \"train\",\n",
    "        return_row=False,\n",
    "    ):\n",
    "        super(EnocderSet, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The target label can be switched to:\n",
    "        PatientSex\n",
    "        PatientAge\n",
    "        PatientSize\n",
    "        PatientWeight\n",
    "        \"\"\"\n",
    "        # load the .csv which was created previously\n",
    "\n",
    "        # self.three_D = three_D\n",
    "        # self.dorsal = dorsal\n",
    "        self.path = path\n",
    "        self.target_label = target_label\n",
    "        self.directory = directory\n",
    "        # self.ind = ind\n",
    "        self.name = \"StyleGAN2-Dataset\"\n",
    "        self.drop_mean = drop_mean\n",
    "        self.region_of_interest = region_of_interest\n",
    "        self.slice = slice\n",
    "        dataframe = pd.DataFrame(pd.read_csv(directory))\n",
    "\n",
    "        if split != \"all\":\n",
    "            dataframe = pd.DataFrame(pd.read_csv(directory))\n",
    "            self.dataset = dataframe.loc[dataframe[\"Split\"] > split]\n",
    "            self.dataset.reset_index(inplace=True)\n",
    "        else:\n",
    "            self.dataset = dataframe\n",
    "        if drop_mean == True:\n",
    "            self.dataset = self.dataset.drop(self.dataset[(self.dataset[\"PatientAge\"] > 27) & (self.dataset[\"PatientAge\"] < 37)].index)\n",
    "            self.dataset.reset_index(inplace=True)\n",
    "        # self.dataset = pd.read_csv(directory)[:ind]\n",
    "\n",
    "        print(\"len = \", len(self.dataset))\n",
    "\n",
    "        self.age_count = self.dataset[\"PatientAge\"].nunique()\n",
    "        self.weight_count = self.dataset[\"PatientWeight\"].nunique()\n",
    "        self.size_count = self.dataset[\"PatientSize\"].nunique()\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.return_row = return_row\n",
    "\n",
    "        length_dict = {\n",
    "            \"PatientSex\": 2,\n",
    "            \"PatientAge\": self.age_count,\n",
    "            \"PatientWeight\": self.weight_count,\n",
    "            \"PatientSize\": self.size_count,\n",
    "        }\n",
    "\n",
    "        self.ind = [2, self.age_count, self.weight_count, self.size_count]\n",
    "\n",
    "        # for keys in length_dict.keys():\n",
    "        #    print(keys + \" dictionary is \", length_dict[keys], \" long\")\n",
    "        self.num_img = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def get_max_files(self, index, roi):\n",
    "        row = self.dataset.iloc[index]\n",
    "        id = f'{row[\"PatientID\"]}_{roi}'\n",
    "        if id not in self.num_img:\n",
    "            p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "            self.num_img[id] = len(list(p2.glob(id + \"_*.png\")))\n",
    "        return self.num_img[id]\n",
    "\n",
    "    def get_item(self, index, slice=None, roi=None):\n",
    "        row = self.dataset.iloc[index]\n",
    "        if roi is None:\n",
    "            roi = self.region_of_interest\n",
    "        if roi == \"random\":\n",
    "            roi = [\"LWS\", \"HWS\", \"BWS\"][random.randint(0, 2)]\n",
    "\n",
    "        p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "        if slice is not None:\n",
    "            i = slice\n",
    "            if self.get_max_files(index, roi) >= i:\n",
    "                return None, []\n",
    "        elif self.slice == \"random\":\n",
    "            i = random.randint(0, self.get_max_files(index, roi) - 1)\n",
    "        elif self.slice == \"center\":\n",
    "            i = self.get_max_files(index, roi) // 2\n",
    "        else:\n",
    "            i = self.slice  # TODO\n",
    "        im_path = Path(p2, f'{row[\"PatientID\"]}_{roi}_{i:02}.png')\n",
    "        # print(im_path)\n",
    "        if not im_path.exists():\n",
    "            raise FileNotFoundError(im_path)\n",
    "\n",
    "        img_array = Image.open(im_path)\n",
    "        img_array = img_array.convert(\"L\")\n",
    "        if self.transform:\n",
    "            img_array = self.transform(img_array)\n",
    "\n",
    "        if self.return_row:\n",
    "            return img_array, row\n",
    "        target = []\n",
    "        if type(self.target_label) == str:\n",
    "            target = self.dataset.loc[index, self.target_label]\n",
    "        elif type(self.target_label) == list:\n",
    "            for i, label in enumerate(self.target_label):\n",
    "                target.append(self.dataset.loc[index, label])\n",
    "\n",
    "        return img_array, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_item(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_path /media/data/robert/code/DiffAE/lightning_logs/DAE_NAKO_256/version_1/checkpoints/last.ckpt\n",
      "[1] Reload Encoder4Editing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/py3.11/lib/python3.11/site-packages/pytorch_lightning/utilities/migration/utils.py:52: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.7, which is newer than your current Lightning version: v2.0.6\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 15.87 M\n",
      "[2] load dataset\n",
      "len =  11188\n",
      "[3] encode dataset\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We found 11189 patients in the NAKO dataset where all three regions exist without duplicate. We initially split the dataset patient wise into train/val/test set 80/5/15\n",
    "We generate with the encoding an embedding for every image. We use the center crop for every image.\n",
    "\n",
    "We concatenate 12 slice to improve our T-SNE plots\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ROWS:\n",
    "    PatientID: str\n",
    "\n",
    "\n",
    "from pl_models.DEA import DAE_LitModel\n",
    "\n",
    "pd_org = pandas.read_csv(root + \"dataset/split.csv\")\n",
    "checkpoint_path = \"/media/data/robert/code/DiffAE/lightning_logs/DAE_NAKO_256/version_1/checkpoints/last.ckpt\"\n",
    "device: str | None = \"cuda:0\"\n",
    "print(\"checkpoint_path\", checkpoint_path)\n",
    "assert Path(checkpoint_path).exists()\n",
    "\n",
    "print(\"[1] Reload Encoder4Editing\")\n",
    "encoder = DAE_LitModel.load_from_checkpoint(checkpoint_path)\n",
    "print(\"[2] load dataset\")\n",
    "transformation = transforms.Compose([transforms.ToTensor(), transforms.CenterCrop(256), transforms.Normalize([0.5], [0.5])])\n",
    "encoder_set = EnocderSet(transform=transformation, return_row=True)\n",
    "# loader = DataLoader(encoder_set, batch_size=4)\n",
    "print(\"[3] encode dataset\")\n",
    "\n",
    "\n",
    "def encode(encoder_set: EnocderSet, id, roi):\n",
    "    real_images, label = encoder_set.get_item(id, slice=None, roi=roi)  # type: ignore\n",
    "    label: ROWS\n",
    "    real_images = torch.as_tensor(real_images, device=device).unsqueeze_(0)  # type: ignore\n",
    "    real_images = real_images.to(device)\n",
    "    latent_code: torch.Tensor = pl_model.model.encode(real_images).to(device)  #\n",
    "    return latent_code, label\n",
    "\n",
    "\n",
    "def encode_multi(encoder_set: EnocderSet, id, roi):\n",
    "    offset = (encoder_set.get_max_files(id, roi) - 12) // 2\n",
    "    label: ROWS = None  # type: ignore\n",
    "    latent_codes = []\n",
    "    for i in range(offset, offset + 12):\n",
    "        real_images, label = encoder_set.get_item(id, slice=None, roi=roi)  # type: ignore\n",
    "        real_images = torch.as_tensor(real_images, device=device).unsqueeze_(0)  # type: ignore\n",
    "        real_images = real_images.to(device)\n",
    "        latent_code: torch.Tensor = pl_model.model.encode(real_images).to(device)  #\n",
    "        latent_codes.append(latent_code)\n",
    "    return torch.cat(latent_codes), label\n",
    "\n",
    "\n",
    "latent_code, label = encode(encoder_set, 0, \"BWS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] encode dataset\n",
      "len =  11188\n",
      "/media/data/robert/code/nako_embedding/dataset/data/test/1095/109574_HWS_00.png\n",
      "/media/data/robert/code/nako_embedding/dataset/data/train/1007/100792_HWS_00.png\n",
      "[5]  11187 /  11188                                             \r"
     ]
    }
   ],
   "source": [
    "print(\"[4] encode dataset\")\n",
    "\n",
    "encoder_set = EnocderSet(transform=transformation, return_row=True, region_of_interest=\"HWS\", slice=\"center\")\n",
    "dic = {}\n",
    "l = len(encoder_set)\n",
    "slice = \"DEA\" if not hessian else \"hessian_DEA\"\n",
    "file = root + f\"/dataset/embeddings_{slice}_stack.pkl\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "if Path(file).exists():\n",
    "    with open(file, \"rb\") as f:\n",
    "        dic = pickle.load(f)\n",
    "        print(len(dic))\n",
    "\n",
    "count = {k: 0 for k in range(20)}\n",
    "with torch.no_grad():\n",
    "    for i in range(l):\n",
    "        count[encoder_set.get_max_files(i, \"LWS\")] += 1\n",
    "        try:\n",
    "            latent_code1, label1 = encode_multi(encoder_set, i, \"HWS\")  #\n",
    "            # print(label.PatientID)\n",
    "            if label1.PatientID in dic:\n",
    "                continue\n",
    "            latent_code2, label2 = encode_multi(encoder_set, i, \"BWS\")\n",
    "            latent_code3, label3 = encode_multi(encoder_set, i, \"LWS\")\n",
    "            assert label1.PatientID == label2.PatientID\n",
    "            assert label1.PatientID == label3.PatientID\n",
    "            dic[label1.PatientID] = (label1, latent_code1.cpu(), latent_code2.cpu(), latent_code3.cpu())\n",
    "            print(f\"[5] {i:6} / {l:6}                                             \", end=\"\\r\")\n",
    "            # assert i + 1 == len(dic), (i + 1, len(dic))\n",
    "            if i % 1001 == 1000:\n",
    "                with open(file, \"wb\") as f:\n",
    "                    pickle.dump(dic, f)\n",
    "        except Exception as e:\n",
    "            # raise e\n",
    "            print(e)\n",
    "with open(file, \"wb\") as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] encode dataset\n",
      "/media/data/robert/code/nako_embedding/dataset/train_hessian_DEA.csv\n",
      "503167\n",
      "{0: 2, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9: 3, 10: 4, 11: 4, 12: 4, 13: 10, 14: 10, 15: 11148, 16: 0, 17: 2, 18: 0, 19: 0}\n"
     ]
    }
   ],
   "source": [
    "extended_list = []\n",
    "\n",
    "print(\"[5] encode dataset\")\n",
    "p = Path(root, f\"dataset/train_{slice}.csv\")\n",
    "print(p)\n",
    "data = []\n",
    "mapping = {\"BWS\": \"thoracic\", \"HWS\": \"cervical\", \"LWS\": \"lumbar\"}\n",
    "for k in dic.keys():\n",
    "    print(k, end=\"\\r\")\n",
    "    for roi in [\"BWS\", \"HWS\", \"LWS\"]:\n",
    "        row = dic[k][0].copy()\n",
    "        id = f'{row[\"PatientID\"]}_{roi}'\n",
    "        p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "        v = len(list(p2.glob(id + \"_*.png\")))\n",
    "        for i in range(v):\n",
    "            row = dic[k][0].copy()\n",
    "            p2 = Path(root, \"dataset/data/\", row[\"Split\"], str(row[\"PatientID\"])[:4])\n",
    "            row[\"file_path\"] = str(Path(p2, f'{row[\"PatientID\"]}_{roi}_{i:02}.png'))\n",
    "            row[\"roi\"] = mapping[roi]\n",
    "\n",
    "            data.append(row.copy())\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(p)\n",
    "# df = pd.concat(data, columns=[\"PatientID\"])\n",
    "# print(df)\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6bb3a75c423b55141fce25809192a6cd1ff47641b121a214d3a7a5d8c58a372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
